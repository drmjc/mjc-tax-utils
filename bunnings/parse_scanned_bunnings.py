#!/usr/bin/env python3
"""
Parse a single (possibly scanned) Bunnings receipt PDF and output a CSV
with the same columns as `parse_bunnings_transactions.py`.

This script attempts text extraction with PyPDF2 first. If the extracted
text is empty or clearly not useful, it falls back to OCR using
`pdf2image` + `pytesseract`.

Usage:
    python3 parse_scanned_bunnings.py receipt.pdf
    python3 parse_scanned_bunnings.py --ocr receipt.pdf   # force OCR

Requirements (for OCR fallback):
    pip install pdf2image pytesseract
    # On macOS, install poppler: brew install poppler
    # Install Tesseract: brew install tesseract

Output:
    Writes a CSV next to the input PDF with the same basename and a `.csv` extension.

Author: generated by GitHub Copilot

WARNING: THIS DOES NOT WORK PERFECTLY YET. OCR OF BUNNINGS RECEIPTS, specifically item descriptions
IS CHALLENGING DUE TO THE LOW PRINT QUALITY AND COMPLEX LAYOUTS. USE AT YOUR OWN RISK.
"""
import sys
import os
import csv
import re
import argparse
import logging

try:
    import PyPDF2
except Exception:
    PyPDF2 = None

try:
    from pdf2image import convert_from_path
    import pytesseract
except Exception:
    convert_from_path = None
    pytesseract = None
try:
    from PIL import Image, ImageFilter, ImageOps
except Exception:
    Image = None
    ImageFilter = None
    ImageOps = None
import difflib


def replace_EACH(text):
    pattern = re.compile(r'(\d)EACH')
    return pattern.sub(r'\1 EACH', text)


def replace_PROMO(text):
    pattern = re.compile(r'(\d)PROMO')
    return pattern.sub(r'\1 PROMO', text)


def is_float(value):
    try:
        value = value.replace(',', '')
        float(value)
        return True
    except Exception:
        return False


def add_space_after_seventh_char(s):
    if len(s) > 7:
        return s[:7] + ' ' + s[7:]
    return s


def get_store(s):
    return "Bunnings " + s.replace(' Warehouse', '')


def ocr_pdf_first_page(pdf_path):
    if convert_from_path is None or pytesseract is None:
        raise RuntimeError('OCR dependencies not available: install pdf2image and pytesseract')
    images = convert_from_path(pdf_path, first_page=1, last_page=1)
    if not images:
        return ''
    text = pytesseract.image_to_string(images[0])
    return text


def preprocess_image_for_ocr(img, upscale=2, median_radius=1, threshold=True):
    if Image is None:
        return img
    # convert to grayscale
    img = img.convert("L")
    # upscale to make small text clearer
    if upscale and upscale != 1:
        w, h = img.size
        img = img.resize((w*upscale, h*upscale), Image.LANCZOS)
    # reduce speckle noise
    if median_radius and median_radius > 0 and ImageFilter is not None:
        img = img.filter(ImageFilter.MedianFilter(size=3))
    # increase contrast / autolevel
    if ImageOps is not None:
        img = ImageOps.autocontrast(img)
    # optionally apply simple thresholding to force black/white
    if threshold:
        img = img.point(lambda p: 255 if p > 160 else 0)
    return img


def ocr_with_preprocessing_first_page(pdf_path, dpi=400, psm=6, oem=1, whitelist=None):
    """Return (full_text, line_tuples) where line_tuples is list of (line_text, avg_conf).
    Requires pdf2image and pytesseract (and Pillow for preprocessing).
    """
    if convert_from_path is None or pytesseract is None:
        raise RuntimeError('OCR dependencies not available: install pdf2image and pytesseract')
    pages = convert_from_path(pdf_path, dpi=dpi, first_page=1, last_page=1)
    if not pages:
        return '', []
    img = pages[0]
    img = preprocess_image_for_ocr(img, upscale=2, median_radius=1, threshold=True)

    cfg = f'--oem {oem} --psm {psm}'
    if whitelist:
        cfg += f' -c tessedit_char_whitelist={whitelist}'

    data = pytesseract.image_to_data(img, config=cfg, output_type=pytesseract.Output.DICT)

    lines = {}
    texts = data.get('text', [])
    confs = data.get('conf', [])
    line_nums = data.get('line_num', [])
    for i, text in enumerate(texts):
        if not text or text.strip() == '':
            continue
        line_num = line_nums[i] if i < len(line_nums) else 0
        conf_s = confs[i] if i < len(confs) else '-1'
        try:
            conf = int(conf_s)
        except Exception:
            try:
                conf = int(float(conf_s))
            except Exception:
                conf = -1
        lines.setdefault(line_num, {'words': [], 'confs': []})
        lines[line_num]['words'].append(text)
        lines[line_num]['confs'].append(conf)

    line_tuples = []
    assembled_text_lines = []
    for ln in sorted(lines):
        words = lines[ln]['words']
        confs_ln = lines[ln]['confs']
        line_text = ' '.join(words)
        good_confs = [c for c in confs_ln if c >= 0]
        avg_conf = sum(good_confs) / max(1, len(good_confs))
        line_tuples.append((line_text, avg_conf))
        assembled_text_lines.append(line_text)

    full_text = '\n'.join(assembled_text_lines)
    return full_text, line_tuples


KNOWN_STORES = [
    'CHATSWOOD WAREHOUSE',
    'BUNNINGS GROUP LIMITED',
    'BUNNINGS',
]


def fix_known_phrases(line):
    # Aggressive normalization and common OCR substitutions to improve fuzzy matching
    s = line.upper()
    # common OCR digit-letter confusions
    subs = [(r'0', 'O'), (r'1', 'I'), (r'5', 'S'), (r'6', 'G')]
    for a, b in subs:
        s = re.sub(a, b, s)
    s = re.sub(r'[^A-Z0-9 ]', ' ', s)
    s = re.sub(r'\s+', ' ', s).strip()
    # try a stricter match first, then a looser one
    match = difflib.get_close_matches(s, KNOWN_STORES, n=1, cutoff=0.65)
    if match:
        return match[0]
    match = difflib.get_close_matches(s, KNOWN_STORES, n=1, cutoff=0.45)
    return match[0] if match else line


def extract_text_from_pdf(pdf_path):
    text = ''
    if PyPDF2 is not None:
        try:
            with open(pdf_path, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                pages = list(reader.pages)
                logging.debug('PyPDF2: %d page(s) found', len(pages))
                for idx, page in enumerate(pages, start=1):
                    try:
                        page_text = page.extract_text() or ''
                    except Exception as e:
                        logging.debug('PyPDF2: failed to extract page %d: %s', idx, e)
                        page_text = ''
                    logging.debug('PyPDF2: page %d extracted text length=%d', idx, len(page_text))
                    text += page_text + '\n'
        except Exception:
            text = ''
    return text


def parse_lines_to_rows(lines):
    headings = [
        "Invoice Date",
        "Store",
        "Item",
        "Quantity",
        "Unit",
        "Description",
        "Your Price",
        "Discount",
        "Amount ex GST",
        "GST",
        "Total Price",
        "Business",
        "Deductable (%)",
        "Deductable ($)",
    ]

    table_rows = [headings]
    invoice_date = None
    store = ''

    i = 0
    while i < len(lines):
        line = lines[i].strip()
        logging.debug('Parsing line %d: %s', i+1, line[:200])
        if not line:
            i += 1
            continue

        low = line.lower()
        if 'invoice date' in low:
            # attempt to extract a date-like token, usually last token
            invoice_date = line.split()[-1]
        if 'warehouse' in low:
            store = get_store(line)

        line = replace_EACH(line)
        line = replace_PROMO(line)

        if 'EACH' in line:
            columns = line.split()
            logging.debug('Found EACH-line: columns=%d', len(columns))

            # If last three aren't numbers, the description likely wrapped
            if len(columns) >= 3 and not all(is_float(col) for col in columns[-3:]):
                if i + 1 < len(lines):
                    logging.debug('Description wrap detected; concatenating next line')
                    line += ' ' + add_space_after_seventh_char(lines[i + 1].strip())
                    columns = line.split()
                    i += 1

            if len(columns) >= 1:
                # Protect against short lines
                if len(columns) >= 4 and columns[-4] in ["NETT", "PROMO"]:
                    columns[-4] = "0%"
                # When parsing fails, attempt a best-effort mapping to expected fields
                # Heuristic: first three columns are Item Quantity Unit, last five are prices/totals
                if len(columns) >= 8:
                    try:
                        columns[-5] = columns[-1]
                    except Exception:
                        pass
                    # Build row: first 3, description (middle), last 5
                    desc = ' '.join(columns[3:-5])
                    row = columns[:3] + [desc] + columns[-5:]
                    if invoice_date:
                        row.insert(0, store)
                        row.insert(0, invoice_date)
                    table_rows.append(row)
                    logging.debug('Appended row: Item=%s Quantity=%s Unit=%s DescLen=%d',
                                  columns[0] if columns else '',
                                  columns[1] if len(columns) > 1 else '',
                                  columns[2] if len(columns) > 2 else '',
                                  len(desc))
        i += 1

    return table_rows


def write_csv(csv_path, rows):
    with open(csv_path, 'w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerows(rows)


def fallback_parse_price_lines(lines, invoice_date=None, store=''):
    """Fallback parser: detect lines that end with a price and build rows.
    Returns a list of rows (excluding header).
    """
    price_re = re.compile(r'\$?\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2})?|\d+)(?:\s*)$')
    rows = []
    seen_prices = set()
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        m = price_re.search(line)
        if m:
            price_raw = m.group(1)
            # try to combine with previous line if that line doesn't end with a price
            combined = line
            if i > 0 and not price_re.search(lines[i-1]):
                combined = (lines[i-1].strip() + ' ' + line).strip()
            # avoid duplicates by price+desc
            key = (price_raw, combined[:80])
            if key in seen_prices:
                i += 1
                continue
            seen_prices.add(key)

            # tokenize and try to extract item code and description
            tokens = combined.split()
            # last token is price, first token might be SKU (mostly digits)
            price_val = price_raw.replace(',', '')
            try:
                price_f = float(price_val)
            except Exception:
                price_f = None

            item = tokens[0] if tokens else ''
            desc_tokens = tokens[1:-1] if len(tokens) > 2 else tokens[:-1]
            desc = ' '.join(desc_tokens).strip()

            # Build row matching headings
            # Invoice Date, Store, Item, Quantity, Unit, Description, Your Price,
            # Discount, Amount ex GST, GST, Total Price, Business, Deductable (%), Deductable ($)
            row = [''] * 14
            if invoice_date:
                row[0] = invoice_date
            row[1] = store or ''
            row[2] = item
            row[3] = '1'  # assume quantity 1 when unknown
            row[4] = ''
            row[5] = desc
            # format price with 2 decimals if we have a numeric value
            if price_f is not None:
                price_str = f'{price_f:.2f}'
                row[6] = price_str
                row[8] = price_str  # Amount ex GST fallback
                row[10] = price_str  # Total Price
            else:
                row[6] = price_raw
                row[8] = price_raw
                row[10] = price_raw
            rows.append(row)
            # if we consumed a previous line, skip it
            if i > 0 and not price_re.search(lines[i-1]):
                i += 2
                continue
        i += 1
    return rows


def main():
    parser = argparse.ArgumentParser(description='Parse a single Bunnings receipt PDF (OCR fallback)')
    parser.add_argument('pdf', help='Input PDF file')
    parser.add_argument('--ocr', action='store_true', help='Force OCR (skip PyPDF2 text extraction)')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    args = parser.parse_args()

    pdf_path = args.pdf
    if not os.path.exists(pdf_path):
        print(f'File not found: {pdf_path}', file=sys.stderr)
        sys.exit(2)

    # configure logging
    if args.debug:
        logging.basicConfig(level=logging.DEBUG, format='[DEBUG] %(message)s')
    else:
        logging.basicConfig(level=logging.INFO, format='%(message)s')

    text = ''
    if not args.ocr:
        logging.info('Attempting text extraction with PyPDF2')
        text = extract_text_from_pdf(pdf_path)
        logging.debug('Total extracted text length=%d', len(text) if text else 0)
        if text and len(text.strip()) > 0:
            logging.debug('First 400 chars of extracted text:\n%s', (text.strip()[:400]))

    # If extracted text is empty or very short, fallback to OCR
    if not text or len(text.strip()) < 80:
        logging.info('Extracted text was short or empty; attempting OCR fallback')
        try:
            # prefer the preprocessing OCR which returns per-line confidences
            try:
                text, line_tuples = ocr_with_preprocessing_first_page(pdf_path, dpi=400, psm=6, oem=1,
                                                                      whitelist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789$().:-/%\"\' )')
            except Exception:
                # fallback to simple OCR
                logging.debug('Preprocessing OCR not available, falling back to simple OCR')
                text = ocr_pdf_first_page(pdf_path)
                line_tuples = [(l, 0) for l in text.split('\n') if l.strip()]
            logging.debug('OCR extracted text length=%d', len(text) if text else 0)
            if text:
                logging.debug('First 400 chars of OCR text:\n%s', text.strip()[:400])
                logging.debug('Sample line confidences: %s', line_tuples[:6])
            # apply fuzzy store fixes on high-confidence lines
            fixed_lines = []
            for ln, conf in line_tuples:
                fixed = fix_known_phrases(ln)
                if fixed != ln:
                    logging.debug("Fixed phrase: '%s' -> '%s' (conf=%s)", ln, fixed, conf)
                fixed_lines.append(fixed)
            if fixed_lines:
                text = '\n'.join(fixed_lines)
        except Exception as e:
            logging.info('OCR failed or not available: %s', e)
            # continue with whatever text we have (may be empty)

    if not text:
        logging.error('No text extracted from PDF; aborting')
        sys.exit(3)

    lines = [l for l in text.split('\n') if l.strip()]
    rows = parse_lines_to_rows(lines)

    # If no rows were found via the strict parser, try the price-line fallback
    if len(rows) <= 1:
        logging.info('No item rows from primary parser; running price-line fallback')
        fallback_rows = fallback_parse_price_lines(lines, invoice_date=None, store='')
        if fallback_rows:
            # insert fallback rows after header
            rows.extend(fallback_rows)
            logging.debug('Fallback added %d row(s)', len(fallback_rows))

    csv_path = os.path.splitext(pdf_path)[0] + '.csv'
    write_csv(csv_path, rows)
    logging.info('Wrote %d transactions to %s', max(0, len(rows)-1), csv_path)


if __name__ == '__main__':
    main()
