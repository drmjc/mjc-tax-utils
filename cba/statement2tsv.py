#!/usr/bin/env python3
"""
Convert a CBA bank statement PDF into a TSV with columns:
Date<TAB>Transaction<TAB>Debit<TAB>Credit<TAB>Balance

Behaviour:
- Skip header until the table header containing 'Date' 'Transaction' 'Debit' 'Credit' 'Balance'
- Treat any line that starts with a date (D/M/YYYY or DD/MM/YYYY) as a new transaction
- Lines that do not start with a date are appended to the last transaction's description (wrap handling)
- Attempt to extract Debit/Credit/Balance amounts from the end of the transaction line

Usage:
    python3 cba/statement2tsv.py input.pdf > out.tsv

Author: generated by Copilot
"""
import sys
import re
import argparse
from typing import List

try:
    import fitz
except Exception:
    fitz = None


DATE_RE = re.compile(r'^(\d{1,2}/\d{1,2}/\d{4}|\d{1,2}\s+[A-Za-z]{3}\s+\d{4}|\d{1,2}\s+[A-Za-z]{3})')
AMOUNT_RE = re.compile(r'\$?\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2})|\d+\.\d{2})$')


def extract_text_with_fitz(pdf_path: str) -> List[List[str]]:
    if fitz is None:
        raise RuntimeError('PyMuPDF (fitz) not available; please install it in the venv')
    doc = fitz.open(pdf_path)
    # return list of pages where each page is a list of lines
    pages_lines = []
    for page in doc:
        # build lines from text blocks only (skip image blocks that may appear before the table)
        pdata = page.get_text('dict')
        lines = []
        for block in pdata.get('blocks', []):
            # block 'type' == 0 is text, 1 is image
            if block.get('type', 0) != 0:
                continue
            for line in block.get('lines', []):
                parts = []
                for span in line.get('spans', []):
                    text = span.get('text', '')
                    if text:
                        parts.append(text.rstrip())
                if parts:
                    lines.append(' '.join(parts).rstrip())
        pages_lines.append(lines)
    return pages_lines


def extract_account_number(pdf_path: str) -> str:
    """Extract account number from the first page of the PDF.
    
    Returns the account number as a string, or empty string if not found.
    Looks for patterns like "Account Number" followed by digits, or
    digit patterns like "06 2799 12930092".
    """
    if fitz is None:
        return ''
    
    try:
        doc = fitz.open(pdf_path)
        if len(doc) == 0:
            return ''
        
        # Get text from first page
        first_page = doc[0]
        text = first_page.get_text()
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        
        # Pattern 1: Look for "Account Number" followed by the number
        account_re = re.compile(r'(?i)account\s+number[:\s]+([\d\s-]{6,})')
        for line in lines:
            match = account_re.search(line)
            if match:
                account_num = match.group(1).strip()
                # Clean up: remove extra spaces, normalize
                account_num = re.sub(r'\s+', ' ', account_num)
                if len(account_num) >= 6:  # Minimum reasonable length
                    doc.close()
                    return account_num
        
        # Pattern 2: Look for digit patterns that match CBA account format (e.g., "06 2799 12930092")
        # CBA accounts typically have format: 2 digits, space, 4 digits, space, 8 digits
        cba_account_re = re.compile(r'\b(\d{2}\s+\d{4}\s+\d{8})\b')
        for line in lines[:50]:  # Check first 50 lines
            match = cba_account_re.search(line)
            if match:
                doc.close()
                return match.group(1)
        
        # Pattern 3: Look for any line with "Account" and digits nearby
        for i, line in enumerate(lines[:30]):
            if 'account' in line.lower():
                # Check current line and next few lines for digit patterns
                search_lines = lines[i:i+3]
                for search_line in search_lines:
                    # Look for sequences of digits with spaces
                    digit_pattern = re.search(r'(\d{2}(?:\s+\d{4}){0,2}(?:\s+\d{8})?)', search_line)
                    if digit_pattern:
                        account_num = digit_pattern.group(1).strip()
                        if len(account_num.replace(' ', '')) >= 6:
                            doc.close()
                            return account_num
        
        doc.close()
    except Exception:
        pass
    
    return ''


def parse_using_blocks(pdf_path: str, debug: bool = False) -> List[List[str]]:
    """Attempt to parse the statement using positional information from PyMuPDF blocks.

    Returns rows as [date, transaction, debit, credit, balance]. This is best-effort
    and falls back to empty list if it cannot locate a usable table header.
    """
    if fitz is None:
        return []
    doc = fitz.open(pdf_path)
    rows: List[List[str]] = []

    # helper: extract spans per line with their x positions
    def page_spans(page):
        pdata = page.get_text('dict')
        out_lines = []
        for block in pdata.get('blocks', []):
            # Skip image blocks (type == 1)
            if block.get('type', 0) != 0:
                continue
            for line in block.get('lines', []):
                spans = []
                ymin = None
                for span in line.get('spans', []):
                    x0, y0, x1, y1 = span.get('bbox', (0,0,0,0))
                    if ymin is None:
                        ymin = y0
                    spans.append({'x0': x0, 'x1': x1, 'xmid': (x0+x1)/2.0, 'text': span.get('text','').strip(), 'y': y0})
                if spans:
                    # sort spans by x0
                    spans = sorted(spans, key=lambda s: s['x0'])
                    out_lines.append(spans)
        return out_lines

    # find header columns by scanning pages for a header line containing 'Date' and 'Transaction'
    # Try to find header on first page, but if not found, continue searching
    col_centers = None
    header_page_idx = None
    header_line_idx = None
    pages_lines_spans = []
    for p_i, page in enumerate(doc):
        pls = page_spans(page)
        pages_lines_spans.append(pls)
        # Only search for header if we haven't found one yet
        if col_centers is None:
            for l_i, spans in enumerate(pls):
                joined = ' '.join(s['text'] for s in spans).lower()
                if ('date' in joined and 'transaction' in joined):
                    # prefer header lines that start with 'date' or have multiple spans or are followed by Debit/Credit/Balance
                    has_table_labels = False
                    for j in range(l_i+1, min(len(pls), l_i+6)):
                        txt = ' '.join(s['text'] for s in pls[j]).lower()
                        if any(k in txt for k in ('debit', 'credit', 'balance')):
                            has_table_labels = True
                            break
                    if joined.lstrip().lower().startswith('date') or len(spans) >= 2 or (has_table_labels and len(joined) < 40):
                        centers = [s['xmid'] for s in spans if s['text'].strip()]
                        col_centers = centers
                        header_page_idx = p_i
                        header_line_idx = l_i
                        if debug:
                            print(f'Found header on page {p_i} line {l_i} centers={centers} labels={has_table_labels}', file=sys.stderr)
                        break

    if not col_centers:
        return []

    # add more centers for right-hand numeric columns by scanning nearby lines for 'Debit','Credit','Balance'
    # look at subsequent lines on the same page
    hdr_pls = pages_lines_spans[header_page_idx]
    for j in range(header_line_idx+1, min(len(hdr_pls), header_line_idx+6)):
        txt = ' '.join(s['text'] for s in hdr_pls[j]).lower()
        if any(k in txt for k in ('debit', 'credit', 'balance')):
            for s in hdr_pls[j]:
                if s['text'].strip():
                    col_centers.append(s['xmid'])
    # normalize and sort unique centers
    col_centers = sorted(list(dict.fromkeys(col_centers)))
    if debug:
        print('Final column centers:', col_centers, file=sys.stderr)

    # determine boundaries between columns (midpoints)
    boundaries = []
    for a,b in zip(col_centers, col_centers[1:]):
        boundaries.append((a+b)/2.0)

    def assign_span_to_col(span):
        x = span['xmid']
        for i, b in enumerate(boundaries):
            if x < b:
                return i
        return len(boundaries)

    # iterate pages and lines after header; for each line build columns by grouping spans
    stopped = False
    current = None  # type: ignore
    current_tokens = []

    def parse_amount_field(a: str):
        if not a:
            return ('', None)
        s = a.replace('$', '').strip()
        # Handle "Nil" or "nil" as zero
        if s.lower() in ('nil', 'nill', 'nil.'):
            return ('0', None)
        m = re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d{1,2})|\d+\.\d{2})', s)
        amt = m.group(1) if m else ''
        low = s.lower()
        kind = None
        if 'cr' in low:
            kind = 'credit'
        elif 'dr' in low or '(' in s or ')' in s:
            kind = 'debit'
        return (amt, kind)

    # helper to strip monetary tokens from a text fragment so the transaction
    # description doesn't accidentally include trailing numeric columns
    AMOUNT_TOKEN_RE = re.compile(r'\$?\s*\d{1,3}(?:,\d{3})*(?:\.\d{2})')
    def strip_amount_tokens(s: str) -> str:
        if not s:
            return s
        return AMOUNT_TOKEN_RE.sub('', s).strip()

    # apply collected numeric tokens to a row: tokens are (amt, kind, col_idx)
    def apply_tokens_to_row(row, tokens):
        if not tokens:
            return row
        if len(tokens) >= 2:
            trans_amt, trans_kind, _ = tokens[0]
            bal, bal_kind, bal_col_idx = tokens[-1]
            # If last token is from balance column (col_idx == 4), it's the balance
            if bal_col_idx != 4:
                # Last token is not balance, look for balance token
                for amt, kind, col_idx in tokens:
                    if col_idx == 4:
                        bal = amt
                        bal_kind = kind
                        break
        else:
            trans_amt, trans_kind, _ = tokens[0]
            bal = None
            bal_kind = None
            # If only one token and it's from balance column (col_idx == 4), treat as balance
            if len(tokens) == 1 and tokens[0][2] == 4:
                bal = trans_amt
                bal_kind = trans_kind
                trans_amt = None

        if len(tokens) == 1 and trans_kind == 'credit' and tokens[0][2] != 4:
            if not row[3]:
                row[3] = trans_amt
            return row

        if bal and not row[4]:
            # If balance token has DR indicator (kind == 'debit'), make it negative
            if bal_kind == 'debit' and bal:
                # Ensure balance is negative for DR
                try:
                    bal_val = float(bal.replace(',', ''))
                    bal = f"-{abs(bal_val):.2f}"
                except Exception:
                    pass
            row[4] = bal

        if trans_amt:
            kind = trans_kind
            if not kind:
                desc = (row[0] + ' ' + row[1]).lower()
                # Check debit keywords first (more specific patterns like "transfer to")
                if any(kw in desc for kw in ('transfer to', 'payment', 'purchase', 'withdrawal', 'bpay', 'afterpay', 'loan repayment')):
                    kind = 'debit'
                elif any(kw in desc for kw in ('credit', 'direct credit', 'transfer from', 'received', 'refund', 'offer', 'homeseeker', 'salary', 'reversal', 'return')):
                    kind = 'credit'
            if kind == 'credit':
                if not row[3]:
                    row[3] = trans_amt
            elif kind == 'debit':
                if not row[2]:
                    row[2] = trans_amt
            else:
                if not row[2]:
                    row[2] = trans_amt
        return row

    for p_i, pls in enumerate(pages_lines_spans):
        # Skip pages before the header page
        if p_i < header_page_idx:
            continue
            
        for l_i, spans in enumerate(pls):
            # skip everything before header line on the header page
            if p_i == header_page_idx and l_i <= header_line_idx:
                continue
                
            # For subsequent pages, skip repeated header lines that appear at the top
            if p_i > header_page_idx:
                joined = ' '.join(s['text'] for s in spans).lower()
                # Skip repeated header lines on subsequent pages (Date Transaction or similar)
                # Check within first 10 lines for header-like content
                if l_i < 10:
                    if (joined.strip() == 'date transaction' or 
                        (joined.lstrip().lower().startswith('date') and 'transaction' in joined and len(joined.strip()) < 60)):
                        if debug:
                            print(f'Skipping repeated header on page {p_i} line {l_i}: {joined[:50]}', file=sys.stderr)
                        continue
                    # Also skip lines that are just "Debit", "Credit", "Balance" (header column labels)
                    if joined.strip() in ('debit', 'credit', 'balance') and l_i < 10:
                        if debug:
                            print(f'Skipping header label on page {p_i} line {l_i}: {joined}', file=sys.stderr)
                        continue
            # build columns
            cols = [''] * (len(col_centers))
            for s in spans:
                idx = assign_span_to_col(s)
                if cols[idx]:
                    cols[idx] += ' ' + s['text']
                else:
                    cols[idx] = s['text']
            if debug:
                print(f'PAGE {p_i} LINE {l_i} COLS={cols}', file=sys.stderr)

            joined_cols = ' '.join(c.lower() for c in cols if c)
            if 'opening balance' in joined_cols and 'total debits' in joined_cols:
                stopped = True
                break
            # Stop when we encounter "closing balance"
            if 'closing balance' in joined_cols:
                stopped = True
                break

            # detect date in first column (or combined first+second)
            date_txt = cols[0].strip()
            is_date = bool(DATE_RE.match(date_txt))
            if not is_date and len(cols) > 1 and DATE_RE.match((cols[0] + ' ' + cols[1]).strip()):
                # join date pieces
                date_txt = (cols[0] + ' ' + cols[1]).strip()
                # shift remaining for easier handling
                cols = [date_txt] + cols[2:]
                is_date = True

            if is_date:
                # finalize previous current row
                if current is not None:
                    current = apply_tokens_to_row(current, current_tokens)
                    # sanitize amounts in current before append
                    def clean_amt(a):
                        if not a:
                            return ''
                        # Preserve negative sign if present
                        is_negative = a.startswith('-')
                        m = re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d{1,2}))', a.replace('$',''))
                        result = m.group(1) if m else a
                        # Restore negative sign if it was present
                        if is_negative and result:
                            result = '-' + result
                        return result
                    current[2] = clean_amt(current[2])
                    current[3] = clean_amt(current[3])
                    # For balance, preserve the value as set by apply_tokens_to_row (which handles DR)
                    # Don't clean it if it's already a formatted negative value
                    if current[4] and not current[4].startswith('-') and not current[4].startswith('$'):
                        current[4] = clean_amt(current[4])
                    elif not current[4]:
                        current[4] = clean_amt(current[4])
                    rows.append(current)
                    current_tokens = []
                # start new current row from this line
                # split the matched date from any trailing text on the same column
                mdate = DATE_RE.match(date_txt)
                if mdate:
                    date = mdate.group(1)
                    remainder = date_txt[mdate.end():].strip()
                    # strip any trailing monetary tokens from the remainder so the
                    # transaction description does not include the numeric columns
                    remainder = strip_amount_tokens(remainder)
                else:
                    date = date_txt
                    remainder = ''
                # build initial transaction from remainder + cols[1]
                tx_parts = []
                if remainder:
                    tx_parts.append(remainder)
                if len(cols) > 1 and cols[1].strip():
                    # also strip amount tokens from the second column if it contains
                    # trailing numeric values
                    tx_parts.append(strip_amount_tokens(cols[1].strip()))
                transaction = ' '.join(tx_parts).strip()
                debit = cols[2].strip() if len(cols) > 2 else ''
                credit = cols[3].strip() if len(cols) > 3 else ''
                balance = cols[4].strip() if len(cols) > 4 else ''
                current = [date, transaction, debit, credit, balance]
                current_tokens = []
                if debug:
                    print(f'START row: {current}', file=sys.stderr)
            else:
                # non-date line: merge into current transaction if present
                if current is None:
                    if debug:
                        print(f'PAGE {p_i} LINE {l_i} skipping (no current): cols={cols}', file=sys.stderr)
                    continue
                # merge descriptive text: prefer cols[1], fallback to cols[0]
                desc_piece = ''
                if len(cols) > 1 and cols[1].strip():
                    desc_piece = cols[1].strip()
                elif cols[0].strip():
                    desc_piece = cols[0].strip()
                if desc_piece:
                    # Filter out metadata patterns (like "4744.29842.1.2 ZZ258R9 0303 SL.R9.S945.D359.OV06.00.30")
                    # These typically contain patterns like numbers with dots, alphanumeric codes, etc.
                    # Skip lines that look like metadata (long alphanumeric strings with dots/slashes)
                    if re.match(r'^[\d\.\s]+[A-Z0-9\s\.\/]+$', desc_piece) and len(desc_piece) > 20:
                        # This looks like metadata, skip it
                        if debug:
                            print(f'Skipping metadata line: {desc_piece[:50]}', file=sys.stderr)
                        continue
                    current[1] = (current[1] + ' ' + desc_piece).strip()
                # merge numeric columns into current amounts
                for col_idx in (2, 3, 4):
                    if len(cols) > col_idx and cols[col_idx].strip():
                        amt, kind = parse_amount_field(cols[col_idx])
                        # Allow "0" for balance (Nil becomes 0)
                        if not amt and col_idx != 4:
                            continue
                        # For balance column, if it's "Nil" or empty, set to "0"
                        if col_idx == 4 and not amt and cols[col_idx].strip().lower() in ('nil', 'nill', 'nil.'):
                            amt = '0'
                        if not amt:
                            continue
                        # record the token for later assignment
                        current_tokens.append((amt, kind, col_idx))
                if debug:
                    print(f'MERGED into current: {current}', file=sys.stderr)
        if stopped:
            break

    # append any final current row
    if current is not None:
        # apply any collected tokens for the final row, then sanitize amounts
        current = apply_tokens_to_row(current, current_tokens)
        def clean_amt(a):
            if not a:
                return ''
            m = re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d{1,2}))', a.replace('$',''))
            return m.group(1) if m else a
        current[2] = clean_amt(current[2])
        current[3] = clean_amt(current[3])
        current[4] = clean_amt(current[4])
        rows.append(current)

    return rows


def find_table_start(lines: List[str]) -> int:
    # find the header which may be on one or multiple lines
    for idx in range(len(lines)-3):
        a = lines[idx].lower()
        b = lines[idx+1].lower()
        c = lines[idx+2].lower()
        d = lines[idx+3].lower()
        # common layout: "Date Transaction" then "Debit" "Credit" "Balance"
        if 'date' in a and 'transaction' in a and 'debit' in b and 'credit' in c and 'balance' in d:
            return idx + 4
    # also accept single-line header
    for idx, line in enumerate(lines):
        low = line.lower()
        if 'date' in low and 'transaction' in low and 'debit' in low and 'credit' in low and 'balance' in low:
            return idx + 1
    return 0


def strip_repeated_headers(pages_lines: List[List[str]]) -> List[str]:
    """Detect lines that repeat across pages (likely headers/footers) and remove them.
    Returns a single list of cleaned lines.
    """
    # collect candidates from first/last N lines of each page
    head_tail_counts = {}
    N = 6
    for pl in pages_lines:
        head = pl[:N]
        tail = pl[-N:]
        for ln in head + tail:
            s = ln.strip()
            if not s:
                continue
            head_tail_counts[s] = head_tail_counts.get(s, 0) + 1

    # consider strings that appear on 2 or more pages as header/footer
    repeated = {s for s,c in head_tail_counts.items() if c >= 2 and len(s) > 3}

    cleaned_pages = []
    for pl in pages_lines:
        cleaned = []
        for ln in pl:
            s = ln.strip()
            # drop page-number and 'Statement' lines
            if re.match(r'(?i)statement\s*\d+', s):
                continue
            # (Page X of Y) or Page X
            if re.search(r'(?i)page\s*\d+(?:\s*of\s*\d+)?', s):
                continue
            # drop very short repeated lines
            if s in repeated:
                continue
            # drop lines that are just 'Account Number' or its value repeated
            if re.match(r'(?i)account number', s) or (re.match(r'^[\d\s-]{6,}$', s) and 'account' in ' '.join(pl[:3]).lower()):
                continue
            cleaned.append(ln)
        cleaned_pages.append(cleaned)

    # flatten cleaned pages to a single list
    out_lines = []
    for pl in cleaned_pages:
        out_lines.extend(pl)
    return out_lines


def split_page_sections(pages_lines: List[List[str]]):
    """Split each page into header, body and footer sections.

    - The body is assumed to start at the first occurrence of a line containing
      both 'Date' and 'Transaction' (case-insensitive) or at a line 'Date' followed
      by a 'Transaction' line below it.
    - Header is everything before the body start; footer is the remainder.
    Returns a list of dicts: [{'header': [...], 'body': [...], 'footer': [...]}, ...]
    """
    pages = []
    for pl in pages_lines:
        # normalize
        lines = [ln.rstrip() for ln in pl]
        body_start = None
        # search for a line that contains both 'date' and 'transaction'
        for i, ln in enumerate(lines):
            low = ln.lower()
            if 'date' in low and 'transaction' in low:
                body_start = i
                break
        # if not found, look for 'Date' followed by 'Transaction' on next few lines
        if body_start is None:
            for i in range(len(lines)-2):
                if 'date' in lines[i].lower() and 'transaction' in lines[i+1].lower():
                    body_start = i
                    break
        # fallback: if page contains 'Date Transaction' string separated, try fuzzy match
        if body_start is None:
            for i, ln in enumerate(lines):
                if ln.strip().lower().startswith('date'):
                    body_start = i
                    break

        if body_start is None:
            # no body found on this page; treat whole page as header/footer (put in header)
            pages.append({'header': lines, 'body': [], 'footer': []})
            continue

        # split into sections
        header = lines[:body_start]
        # body runs until the end of the page (footers are rare/blank); we'll allow caller to drop repeated footers
        body = lines[body_start:]
        # drop the table header rows that often appear at the start of the body on each page
        # e.g. a line containing both 'Date' and 'Transaction' and following lines 'Debit', 'Credit', 'Balance'
        k = 0
        if body:
            bl0 = body[0].lower()
            if 'date' in bl0 and 'transaction' in bl0:
                k = 1
                # optionally skip the next three header lines if they exist
                for j in range(1, 4):
                    if k < len(body) and body[k].strip().lower() in ('debit', 'credit', 'balance'):
                        k += 1
        if k:
            body = body[k:]
        footer = []
        pages.append({'header': header, 'body': body, 'footer': footer})

    return pages


def split_columns_by_spacing(s: str) -> List[str]:
    # split by two or more spaces (table-like spacing)
    parts = re.split(r'\s{2,}', s.strip())
    return [p.strip() for p in parts if p.strip()]


def parse_statement_lines(lines: List[str]) -> List[List[str]]:
    # A simpler, more robust parser flow:
    # - accept either pages (list of list) or flattened lines
    # - find table start, infer statement year
    # - perform a cleaning pass merging numeric fragments
    # - detect date-started blocks and extract amounts
    rows: List[List[str]] = []

    # if caller passed pages_lines (list of lists), flatten and clean headers
    if lines and isinstance(lines[0], list):
        pages = lines
        lines = strip_repeated_headers(pages)

    # find where the transaction table starts
    table_start = find_table_start(lines)
    if table_start <= 0:
        for i, l in enumerate(lines):
            if DATE_RE.search(l):
                table_start = i
                break

    # infer statement year from the period string if present
    stmt_year = None
    for l in lines[:40]:
        m = re.search(r'(\d{1,2}\s+[A-Za-z]{3}\s+\d{4})\s*-\s*(\d{1,2}\s+[A-Za-z]{3}\s+\d{4})', l)
        if m:
            try:
                stmt_year = int(m.group(2).split()[-1])
            except Exception:
                stmt_year = None
            break

    # fallback: also try to find any explicit year in the first 60 lines
    if stmt_year is None:
        for l in lines[:60]:
            m = re.search(r'\b\d{1,2}\s+[A-Za-z]{3}\s+(\d{4})\b', l)
            if m:
                try:
                    stmt_year = int(m.group(1))
                    break
                except Exception:
                    continue

    # cleaning pass: merge decimal fragments and simple noisy tokens
    cleaned: List[str] = []
    i = 0
    while i < len(lines):
        s = lines[i].strip()
        if not s:
            i += 1
            continue
        if s == '(':
            i += 1
            continue
        # join a thousands-only line with following decimal fragment
        if re.match(r'^\d{1,3}(?:,\d{3})*$', s) and i+1 < len(lines) and re.match(r'^[\.,]?\d{1,2}$', lines[i+1].strip()):
            cleaned.append(s + lines[i+1].strip())
            i += 2
            continue
        # if line is a short decimal fragment, merge into previous
        if re.match(r'^[\.,]?\d{1,2}$', s) and cleaned:
            cleaned[-1] = cleaned[-1] + s
            i += 1
            continue
        # if line starts with decimal fragment but has trailing text, split it
        m_frag = re.match(r'^([\.,]?\d{1,2})\s+(.+)$', s)
        if m_frag and cleaned:
            frag = m_frag.group(1)
            rest = m_frag.group(2)
            # only merge if the fragment begins with a dot ('.26') or the previous
            # cleaned line ends with a digit (likely a broken numeric)
            if frag.startswith('.') or re.search(r'\d$', cleaned[-1]):
                cleaned[-1] = cleaned[-1] + frag
                cleaned.append(rest)
                i += 1
                continue
        cleaned.append(s)
        i += 1

    lines = cleaned

    # collect indices of lines that start with dates
    date_indices = []
    for idx in range(table_start, len(lines)):
        if DATE_RE.match(lines[idx].strip()):
            if re.match(r'(?i)value date', lines[idx].strip()):
                continue
            date_indices.append(idx)
    if not date_indices:
        return rows

    credit_kw = ['transfer from', 'direct credit', 'credit', 'received', 'refund', 'transfer in', 'salary', 'reversal', 'return']
    debit_kw = ['transfer to', 'payment', 'purchase', 'card', 'withdrawal', 'bpay', 'afterpay', 'loan repayment']

    for i, start_idx in enumerate(date_indices):
        end_idx = date_indices[i+1] if i+1 < len(date_indices) else len(lines)
        block = [lines[j].strip() for j in range(start_idx, end_idx) if lines[j].strip()]
        if not block:
            continue
        # Stop if we encounter "closing balance"
        merged_block = ' '.join(block).lower()
        if 'closing balance' in merged_block:
            break
        first = block[0]
        m = DATE_RE.match(first)
        date = m.group(1) if m else ''
        if date and re.match(r'^\d{1,2}\s+[A-Za-z]{3}$', date) and stmt_year:
            date = f"{date} {stmt_year}"

        remainder = first[m.end():].strip() if m else first
        # strip any monetary tokens that may be on the same line as the date so
        # they don't become part of the transaction description
        AMOUNT_TOKEN_RE = re.compile(r'\$?\s*\d{1,3}(?:,\d{3})*(?:\.\d{2})')
        def strip_amount_tokens_local(s: str) -> str:
            if not s:
                return s
            return AMOUNT_TOKEN_RE.sub('', s).strip()

        desc_parts = []
        if remainder:
            desc_parts.append(strip_amount_tokens_local(remainder))

        amount_lines = []
        for ln in block[1:]:
            if re.search(r'\bCR\b|\bDR\b', ln, flags=re.I) or re.search(r'\$\s*\d', ln):
                amount_lines.append(ln)
            elif re.search(r'Value Date', ln, flags=re.I) or re.search(r'Card xx', ln, flags=re.I):
                desc_parts.append(ln)
            else:
                desc_parts.append(ln)

        merged = ' '.join(block)
        merged = re.sub(r'\s+\(\s*\)', ' ', merged)
        amt_matches = list(re.finditer(r'\$?\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2}))', merged))
        bal = ''
        amt_vals: List[str] = []
        if amt_matches:
            bal = amt_matches[-1].group(1)
            for m_amt in amt_matches[:-1]:
                amt_vals.append(m_amt.group(1))

        debit = ''
        credit = ''
        if len(amt_vals) >= 2:
            debit = amt_vals[0]
            credit = amt_vals[1]
        elif len(amt_vals) == 1:
            desc_text = ' '.join(desc_parts).lower()
            # Check debit keywords first (more specific patterns like "transfer to")
            if any(kw in desc_text for kw in debit_kw):
                debit = amt_vals[0]
            elif any(kw in desc_text for kw in credit_kw):
                credit = amt_vals[0]
            else:
                debit = amt_vals[0]

        trans = ' '.join(desc_parts).strip()
        rows.append([date, trans, debit, credit, bal])

    return rows


def write_tsv(rows: List[List[str]], out, account_number: str = ''):
    """Write TSV with signed Amount column: Date, Account Number, Transaction, Amount, Balance.

    `rows` is expected to be a list of [Date, Transaction, Debit, Credit, Balance]
    (Debit/Credit are normalized numeric strings or empty). We compute Amount =
    Credit - Debit and format with two decimals.
    `account_number` is added as a column after Date and before Transaction.
    """
    header = ['Date', 'Account Number', 'Transaction', 'Amount', 'Balance']
    out.write('\t'.join(header) + '\n')

    def parse_num(s: str) -> float:
        if not s:
            return 0.0
        try:
            return float(s)
        except Exception:
            try:
                return float(s.replace(',', ''))
            except Exception:
                return 0.0

    for r in rows:
        # r: [date, transaction, debit, credit, balance]
        debit = parse_num(r[2])
        credit = parse_num(r[3])
        amount = credit - debit
        amount_s = f"{amount:.2f}"
        balance = r[4] or ''
        out.write('\t'.join([r[0], account_number, r[1], amount_s, balance]) + '\n')


def main():
    parser = argparse.ArgumentParser(description='Convert CBA statement PDF to TSV')
    parser.add_argument('pdf', help='Input PDF file')
    parser.add_argument('--out', help='Output TSV path (default: replace .pdf with .tsv)')
    parser.add_argument('--debug', action='store_true', help='Show debug info')
    args = parser.parse_args()

    if args.debug:
        print('Reading:', args.pdf, file=sys.stderr)
    extracted = extract_text_with_fitz(args.pdf)
    # If extract returned per-page lines, split pages into sections and use bodies
    if isinstance(extracted, list) and extracted and isinstance(extracted[0], list):
        pages = split_page_sections(extracted)
        # build flattened lines using only page bodies, drop headers/footers
        flat = []
        stop_lower = 'opening balance'
        stop_extra = 'total debits'
        stopped = False
        for p in pages:
            for ln in p['body']:
                # stop processing when we hit the opening-balance / totals summary line
                low = ln.lower()
                if stop_lower in low and stop_extra in low:
                    stopped = True
                    break
                # also stop if the line starts with 'opening balance' (looser)
                if low.strip().startswith('opening balance'):
                    stopped = True
                    break
                # stop when we encounter "closing balance"
                if 'closing balance' in low:
                    stopped = True
                    break
                flat.append(ln)
            if stopped:
                break
        lines = flat
    else:
        # fallback: treat as raw text
        text = extracted if isinstance(extracted, str) else ''
        lines = [l.rstrip() for l in text.split('\n')]

    if args.debug:
        print('Total body lines to parse:', len(lines), file=sys.stderr)
    # infer statement year from the page text so dates without year can be expanded
    stmt_year = None
    for l in lines[:40]:
        m = re.search(r'(\d{1,2}\s+[A-Za-z]{3}\s+\d{4})\s*-\s*(\d{1,2}\s+[A-Za-z]{3}\s+\d{4})', l)
        if m:
            try:
                stmt_year = int(m.group(2).split()[-1])
            except Exception:
                stmt_year = None
            break
    if stmt_year is None:
        for l in lines[:60]:
            m = re.search(r'\b\d{1,2}\s+[A-Za-z]{3}\s+(\d{4})\b', l)
            if m:
                try:
                    stmt_year = int(m.group(1))
                    break
                except Exception:
                    continue
    # Extract account number from first page
    account_number = ''
    if fitz is not None:
        account_number = extract_account_number(args.pdf)
        if args.debug and account_number:
            print(f'Account number: {account_number}', file=sys.stderr)
    
    # Try positional block parsing first (more robust). Fall back to line parsing when it fails.
    rows = []
    if fitz is not None:
        try:
            rows = parse_using_blocks(args.pdf, debug=args.debug)
            if args.debug:
                print('Rows from block parser:', len(rows), file=sys.stderr)
        except Exception as e:
            if args.debug:
                print('Block parser failed:', e, file=sys.stderr)
            rows = []

    if not rows:
        rows = parse_statement_lines(lines)
    if args.debug:
        print('Parsed rows:', len(rows), file=sys.stderr)

    # Normalization: strip commas, interpret parentheses/DR/CR hints, format two decimals
    def normalize_cell(s: str) -> str:
        if not s:
            return ''
        t = s.strip()
        # Handle "Nil" or "nil" as zero
        if t.lower() in ('nil', 'nill', 'nil.'):
            return '0.00'
        # detect parentheses (negative) or DR/CR markers
        negative = False
        low = t.lower()
        if '(' in t and ')' in t:
            negative = True
        if ' dr' in low or low.endswith(' dr') or low.endswith('dr'):
            negative = True
        # CR typically means credit (positive)
        # remove non-numeric characters except dot, comma and minus
        cleaned = re.sub(r'[^0-9\.,\-]', '', t)
        # remove commas
        cleaned = cleaned.replace(',', '')
        if cleaned == '':
            return ''
        try:
            val = float(cleaned)
        except Exception:
            return cleaned
        if negative:
            val = -abs(val)
        # format with two decimals, no thousands separator
        return f"{val:.2f}"

    # apply normalization to amount columns (Debit, Credit, Balance)
    norm_rows: List[List[str]] = []
    for r in rows:
        d = normalize_cell(r[2])
        c = normalize_cell(r[3])
        # Check for DR in original balance before normalizing
        b_raw = r[4]
        has_dr = False
        if b_raw:
            b_lower = b_raw.lower()
            if ' dr' in b_lower or b_lower.endswith(' dr') or b_lower.endswith('dr'):
                has_dr = True
        b = normalize_cell(r[4])
        # If original had DR, make balance negative
        if has_dr and b and b != '0.00':
            try:
                b_val = float(b)
                b = f"{-abs(b_val):.2f}"
            except Exception:
                pass
        norm_rows.append([r[0], r[1], d, c, b])

    # convert Date field to DD/MM/YYYY format where possible
    month_map = {
        'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05', 'jun': '06',
        'jul': '07', 'aug': '08', 'sep': '09', 'sept': '09', 'oct': '10', 'nov': '11', 'dec': '12'
    }
    def format_date_to_ddmmyyyy(s: str, fallback_year=None) -> str:
        if not s:
            return s
        s = s.strip()
        # already in DD/MM/YYYY or D/M/YYYY
        mslash = re.match(r'^(\d{1,2})\/(\d{1,2})\/(\d{4})$', s)
        if mslash:
            d = int(mslash.group(1)); mm = int(mslash.group(2)); yyyy = int(mslash.group(3))
            return f"{d:02d}/{mm:02d}/{yyyy}"
        # patterns like '25 Aug 2020' or '3 Nov 2020' or '03 Nov'
        m = re.match(r'^(\d{1,2})\s+([A-Za-z]{3,9})(?:\s+(\d{4}))?$', s)
        if m:
            day = int(m.group(1))
            mon = m.group(2).lower()
            year = None
            if m.group(3):
                try:
                    year = int(m.group(3))
                except Exception:
                    year = None
            if year is None:
                year = fallback_year
            mm = month_map.get(mon[:3], None)
            if mm and year:
                return f"{day:02d}/{mm}/{year}"
        # last resort: return original
        return s

    for r in norm_rows:
        r[0] = format_date_to_ddmmyyyy(r[0], stmt_year)

    # Balance-consistency inference: infer missing debit/credit using running balance deltas
    # convert balances to floats where possible
    def to_float(s: str):
        if not s:
            return None
        # Handle "Nil" or "nil" as zero
        if s.lower().strip() in ('nil', 'nill', 'nil.'):
            return 0.0
        try:
            return float(s)
        except Exception:
            try:
                return float(s.replace(',', ''))
            except Exception:
                return None

    prev_balance = None
    for i, r in enumerate(norm_rows):
        bal = to_float(r[4])
        # if both debit and credit empty but we have prev and curr balance, infer transaction amount
        if not r[2] and not r[3] and prev_balance is not None and bal is not None:
            delta = bal - prev_balance
            # treat positive delta as credit, negative as debit
            if abs(delta) > 0.0001:
                if delta > 0:
                    r[3] = f"{delta:.2f}"
                else:
                    r[2] = f"{abs(delta):.2f}"
        prev_balance = bal if bal is not None else prev_balance

    # Reformat existing balances to two decimals, leave genuinely missing as blank.
    # Note: DR handling is already done in normalize_cell, so we just need to ensure proper formatting
    for r in norm_rows:
        b = r[4]
        if b:
            # Handle "Nil" or "nil" as zero
            if b.lower().strip() in ('nil', 'nill', 'nil.'):
                r[4] = '0.00'
                continue
            # Balance should already be normalized (including DR handling), just ensure proper format
            try:
                vb = float(b)
                r[4] = f"{vb:.2f}"
            except Exception:
                try:
                    vb = float(b.replace(',', ''))
                    r[4] = f"{vb:.2f}"
                except Exception:
                    r[4] = ''
        else:
            r[4] = ''

    # Aggressive inference: if a row has no Balance but has Debit/Credit values and
    # we know the previous running balance, compute current balance = prev + credit - debit.
    prev_bal = None
    for r in norm_rows:
        # update prev_bal when available
        if r[4]:
            try:
                prev_bal = float(r[4])
            except Exception:
                try:
                    prev_bal = float(r[4].replace(',', ''))
                except Exception:
                    prev_bal = None
            continue

        # r[4] is blank here; attempt to infer if debit/credit present and prev_bal known
        if prev_bal is not None:
            d = to_float(r[2]) or 0.0
            c = to_float(r[3]) or 0.0
            if r[2] or r[3]:
                calc = prev_bal + c - d
                r[4] = f"{calc:.2f}"
                prev_bal = calc
            else:
                # cannot infer; leave blank
                r[4] = ''
        else:
            # still unknown, leave blank
            r[4] = ''

    # determine output path: default to input filename with .tsv extension unless --out provided
    out_path = args.out if hasattr(args, 'out') and args.out else None
    if out_path is None:
        if args.pdf.lower().endswith('.pdf'):
            out_path = args.pdf[:-4] + '.tsv'
        else:
            out_path = args.pdf + '.tsv'

    # write to file by default
    try:
        with open(out_path, 'w', encoding='utf-8') as fh:
            write_tsv(norm_rows, fh, account_number)
        if args.debug:
            print('Wrote TSV to', out_path, file=sys.stderr)
    except Exception as e:
        # fallback to stdout
        if args.debug:
            print('Failed to write TSV to', out_path, 'falling back to stdout:', e, file=sys.stderr)
        write_tsv(norm_rows, sys.stdout, account_number)


if __name__ == '__main__':
    main()
